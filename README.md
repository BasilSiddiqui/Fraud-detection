# ğŸ” Insurance Fraud Detection Using Machine Learning

## ğŸ§  What is This Project?

This project is a complete end-to-end solution to **detect fraudulent insurance claims** using machine learning. The dataset is derived from a real-world-like auto insurance claims dataset and includes details about policies, incidents, and claimant behavior.

Using techniques from data science, this project:
- ğŸ“¦ Cleans and preprocesses raw insurance data  
- ğŸ§  Engineers new features for better insight  
- ğŸš€ Trains and evaluates 5 ML models  
- ğŸ“ˆ Visualizes key metrics and outputs predictions  
- âœ… Enables predictions on new unseen CSV files  

---

## â“ Why Fraud Detection Matters

Fraudulent insurance claims cost the industry **billions** annually, driving up premiums for honest policyholders. By identifying fraudulent claims early, insurers can:
- Save time and money  
- Improve decision-making  
- Maintain fairness for genuine customers  

---

## âš™ï¸ How it Works

### ğŸ”¹ 1. Data Cleaning & Preprocessing
- Missing values like `"?"` are replaced with appropriate values (e.g. mode).
- Dates (`policy_bind_date`, `incident_date`) are converted to `datetime` format.
- New features are created from dates like `days_policy_to_incident`.

### ğŸ”¹ 2. Feature Engineering
- Irrelevant or identifier columns are dropped.
- Categorical features are converted using **one-hot encoding**.
- Data is split into training & test sets.
- Numerical values are **standardized** using `StandardScaler`.

### ğŸ”¹ 3. Model Training
Trained and compared the following models:
- ğŸ§  Support Vector Machine (SVC)  
- ğŸŒ² Random Forest  
- ğŸŒ¿ Decision Tree  
- ğŸ AdaBoost  
- ğŸ‘¥ K-Nearest Neighbors

Evaluation metrics used:
- Accuracy, Precision, Recall, F1-Score  
- ROC AUC Score (for ranking classifiers)

### ğŸ”¹ 4. Model Evaluation
Metrics and a confusion matrix help evaluate model performance and misclassification.

### ğŸ”¹ 5. Feature Importance
Top predictors of fraud are extracted using **Random Forestâ€™s feature importance** method.

### ğŸ”¹ 6. Predicting New Data
The best model (based on ROC AUC) is used to predict **fraud likelihood** from a new CSV file.

---

## ğŸ“¸ Visual Results

### ğŸ“Š 1. Missing Value Visualization
![Missing Values](images/MissingValue.png)

### ğŸ”¥ 2. Correlation Heatmap
![Correlation Heatmap](images/CorrelationHeatmap.png)

### ğŸŒ² 3. Top 15 Features - Random Forest
![Top 15 Features](images/Top15Features.png)

### ğŸ§¾ 4. Confusion Matrix - Best Model
![Confusion Matrix](images/ConfusionMatrix.png)

---

## ğŸ§ª Example: Predicting on New Data

```python
new_data = pd.read_csv("new_claims.csv")
# [Preprocessing steps]
new_data_scaled = scaler.transform(new_data_encoded)
predictions = best_model.predict(new_data_scaled)
probs = best_model.predict_proba(new_data_scaled)[:, 1]
````

ğŸ“Œ Output:

```
   fraud_predicted  fraud_probability
0                1           0.504274
1                1           1.000000
...
```

---

## ğŸ“ Files in this Project

| File                           | Description                   |
| ------------------------------ | ----------------------------- |
| `insurance_claims.csv`         | Main dataset                  |
| `insurance_fraud_detection.py` | Core logic & model training   |
| `new_claims.csv`               | Example input for predictions |
| `README.md`                    | This documentation            |
| `output_predictions.csv`       | Results on new data           |

---

## ğŸ”® Future Improvements

* ğŸ§± Implement XGBoost and LightGBM models
* ğŸŒ Deploy via Streamlit for an interactive web app
* ğŸ’¾ Save model with `joblib` for reuse
* ğŸ’¬ Add SHAP explainability to interpret predictions
* ğŸ•µï¸ Automate model selection using GridSearchCV

---

## ğŸ§‘â€ğŸ’» Author

**Basil Rehan**
Data Analyst @ Integra Investment Group | Data Science Student
ğŸ“« [LinkedIn](https://linkedin.com/in/basilrehan)
